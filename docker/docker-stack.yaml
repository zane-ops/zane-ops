services:
  proxy:
    image: ghcr.io/zane-ops/proxy:canary
    command: caddy run --resume
    logging:
      driver: "fluentd"
      options:
        mode: "non-blocking"
        fluentd-address: "unix://$HOME/.fluentd/fluentd.sock"
        fluentd-async: "true"
        fluentd-max-retries: 10
        fluentd-sub-second-precision: "true"
        tag: '{"service_id":"zane.proxy"}'
    deploy:
      replicas: 1
      update_config:
        parallelism: 1
        delay: 5s
        order: start-first
        failure_action: rollback
      restart_policy:
        condition: any
      placement:
        constraints:
          - node.role==manager
      labels:
        zane.role: "proxy"
    ports:
      - target: 80
        published: 80
        protocol: tcp
        mode: host
      - target: 443
        published: 443
        protocol: tcp
        mode: host
      - "2019:2019"
    volumes:
      - caddy-data:/data
      - caddy-config:/config
    environment:
      CADDY_ADMIN: 0.0.0.0:2019
    networks:
      zane:
        aliases:
          - zane.proxy
  temporal-admin-tools:
    image: temporalio/admin-tools:1.24.2-tctl-1.18.1-cli-1.0.0
    environment:
      - DB=postgres12
      - DB_PORT=5432
      - POSTGRES_USER=postgres
      - POSTGRES_PWD=password
      - POSTGRES_SEEDS=zane.db
      - SKIP_SCHEMA_SETUP=false
      - SKIP_DB_SETUP=false
      - SERVICES=history,matching,frontend,worker
      - TEMPORAL_HOME=/etc/temporal
      - TEMPORAL_ADDRESS=zane.temporal:7233
      - TEMPORAL_CLI_ADDRESS=zane.temporal:7233
      - DYNAMIC_CONFIG_FILE_PATH=config/dynamicconfig/development-sql.yaml
      - BIND_ON_IP=0.0.0.0
    volumes:
      - "./temporalio/admin-tools-entrypoint.sh:/etc/temporal/setup.sh"
    entrypoint:
      - /etc/temporal/setup.sh
    deploy:
      mode: replicated-job
      restart_policy:
        condition: on-failure
    networks:
      - zane
volumes:
  caddy-data:
  caddy-config:
networks:
  zane:
    external: true
